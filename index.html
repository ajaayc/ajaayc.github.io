<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Ajaay's Personal Page</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/resume.min.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="css/custom.css">

  </head>

  <body id="page-top">

    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">Ajaay's Personal Page</span>
        <span class="d-none d-lg-block">
     		<!-- had img-profile -->			
          <img class="img-fluid rounded-circle mx-auto mb-2" src="img/profile3.JPG" alt="">
        </span>
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About Ajaay</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#projects">Projects</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#other">Other Work</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#misc">Misc. Stuff</a>
          </li>

       </ul>
      </div>
    </nav>

    <div class="container-fluid p-0">

      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <h1 class="mb-0">Ajaay
            <span class="text-primary">Chandrasekaran</span>
          </h1>
          <div class="subheading mb-5">
			  <a href="mailto:ajaay@umich.edu">ajaay [at] umich.edu</a>
          </div>
		  <p class="mb-5">
            Greetings! Welcome to my personal page.
            <br>
            <br>
            I am an aspiring roboticist with a background in software development and mathematics. I pursued my bachelors in computer science and my masters in electrical and computer engineering at the University of Michigan in Ann Arbor, MI.

            <br>
            <br>
            
            My first name <i>Ajaay</i> is a modification of the Indian name <a href="https://en.wikipedia.org/wiki/Ajay_(given_name)"><i>Ajay</i></a>. I respond to many pronunciations of it and have no preference for any of them. The most common pronunciations are Ay-Jay (AJ), Uhh-Jay, and Uhh-Jie. <br><br>
            My last name <i>Chandrasekaran</i> is based on the Indian name <a href="https://en.wikipedia.org/wiki/Chandrasekhar"> <i> Chandrasekhar</i></a>. I pronounce it as Chan-dra-say-ker-in.
		  </p>
          <ul class="list-inline list-social-icons mb-0">
            <li class="list-inline-item">
              <a href="https://www.linkedin.com/in/ajaayc/">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://github.com/ajaayc">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://www.youtube.com/channel/UC9jhtzfx7DT13GaAtRYHtLg">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-youtube-play fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <br>
        </div>
      </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="projects">
        <div class="my-auto">
          <h2 class="mb-5">Projects</h2>
          <p> 

		  <p><strong>MDOT Lane Marking Evaluation</strong></p>
          [Code]<br>
          <br>
          <center>
            <div class="vid">
              <img src="img/velodyne.png" width="400;">
              <img src="img/mobileye.JPG" width="400;"><br><br>
	        </div>
          </center>
          <br>

          As a research assistant at the University of Michigan Transportation Research Institute in Ann Arbor, MI, I worked under Dr. <a href="https://sites.google.com/view/danielpark/home">Daniel Park</a> on a project to evaluate the effectiveness of various road lanemarking materials. The project was funded by the Michigan Department of Transportation (MDOT).<br><br>

          In 2017, a section of the US-23 highway between Ann Arbor, MI and Brighton, MI was paved with different lanemarking materials along different stretches. We planned to perform a study over a 2-year period to determine how well each lanemarking material on the highway lasted over time; we expected that the different stretches of the highway would be impacted similarly by various environmental factors, such as temperature and precipitation.

          <br><br>
          To achieve our goal we required a method to take measurements of the lanemarkings' conditions on the US-23 highway once during each month so that after the 2-year period we could retrospectively analyze how the lanemarkings' conditions changed over time. Our solution to this problem was to equip a Honda Accord car with various sensors, including:
          <ul>
            <li>Novatel GPS</li>
            <li><a href="https://quanergy.com/m8/">Quanergy M-8 Lidar</a></li>
            <li><a href="https://www.mobileye.com/en-us/">Mobileye unit</a></li>
            <li>Camera</li>
          </ul>
          We proceeded to then engineer a software system that would be executed on the car to collect data of the road conditions from each of these sensors while a human operator drove the car along the US-23 highway once each month.
          <br><br>
          <center>
            <img src="img/ajaayCar.JPG" width="400;">
          </center>
          <br><br>

          For this project, I developed multi-threaded C++ code utilizing the VTK and PCL libraries to extract, interpret, and visualize data collected from our Lidar. We experimented with two Lidar's: The Quanergy M-8 and the Velodyne HDL-64E. Each of these Lidars outputs [x,y,z] point clouds of their surroundings as well as point <a href="http://desktop.arcgis.com/en/arcmap/10.3/manage-data/las-dataset/what-is-intensity-data-.htm">intensities</a>. We were mostly interested in examining the point intensity measurements of the landmarkings. In theory, we could see how the intensity values of the points representing lanemarkings changed over time. The degradation of the highway pavement by the Michigan weather would result in lower intensity points returned by the Lidar for various lanemarking materials.

          <br><br>
          I also developed C++ code to interface with our car's Mobileye unit via the vehicle's CAN message network. The Mobileye communicated data regarding the status of the left and right lanemarkings on the road in front of the driver. Its data arrived in real time as a sequence of bytes that needed to be converted into a human readable format.
          <br><br>
          Finally, I facilated the collection of data from all four of our sensors simultaneously by helping to create a single module that would run all four sensor collection programs together as individual threads of a single CPU process. The module ran on a single HP i7 laptop during each of the car's monthly drives.
          <br><br>
          I was very proud of our final software system. This project necessitated a wonderful combination of both robotics and computer science knowledge.<br><br>
          <center>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/agMfXfZdug4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </center>
          
          <br><br>

		  <p><strong>Collision Estimation for Safe Planning</strong></p>
          [<a href="resources/ajaay_paper.pdf">Paper</a>]<br>
          [Code]
          <center>
            <img src="img/env_setup.png" width="400px;">
            <img src="img/motion_pic.PNG" width="400px;">
          </center>
          <br>
          For my Motion Planning course, I devised and implemented a Gaussian Mixture Model-based algorithm in C++ to expand upon existing methods to estimate the probability that a robot following a pre-generated motion plan would collide with an obstacle.
          <br><br>
          The motivation for this work is that a robot can benefit from quantifying the approximate safety of a motion plan before executing it. While a motion planner should generate a collision-free path, collisions may be possible as the robot follows the path due to natural uncertainty in the data it receives from its sensors and random noise in how it makes movements. Given a probability of collision before executing a motion plan, a robot can either execute it or revise the plan until it can find a "safer" plan.<br><br>

          Existing methods to compute the exact probability of collision for a motion plan rely on running thousands of Monte-Carlo simulations of the robot following the motion plan, which is computationally expensive. The goal of this work is to accurately estimate the probability of collision in a shorter amount of time.

          <br><br>
          For this work, I utilized the OpenRAVE simulation framework and Armadillo C++ linear algebra library to simulate a linear feedback controller and an Extended Kalman Filter estimate for the position of a PR2 robot as it attempted to follow a pre-generated motion plan. I performed experiments to examine my algorithm's performance and presented my research in a paper and a conference talk.
          <br>
          <br>
          Unfortunately, my algorithm did not perform as well as I had hoped, but I learned much from the experience in regards to conducting independent research. I plan to work more on my algorithm in the future to improve its accuracy in estimating a probability of collision for a motion plan.
          <br><br>

		  <p><strong>Deep Neural Network Vehicle Detection System</strong></p>
          [<a href="https://github.com/ajaayc/Car_Detection/blob/master/Perception%20Final%20Report.pdf">Report</a>]<br>
          [<a href="https://github.com/ajaayc/Car_Detection">Code</a>]<br>
          <br>
          <center>
            <img src="img/carBox.jpg" width="400px;">
            <img src="img/graph.png" width="400px;">
          </center><br>
          For my Self-Driving Cars course, I worked in a team to implement a classifier to count the number of cars in an arbitrary image generated from Grand Theft Auto (GTA) simulation. We utilized the TensorFlow Python Object Detector API on AWS EC2 GPU instances to train a fast-RCNN with 50 layers. We trained the RCNN on ~ 6,000 training images with known bounding box locations of cars and we specified two classifications for a detected object: {Car, Not Car}.

          <br><br>
          Using our model, my team ranked 5th place among 35 teams in the class competition by achieving a 63% mean absolute error on the instructor's test set of GTA images with unknown car counts.
          <br><br>

	  <p><strong>Mobile Robotics iSAM Implementation</strong></p>
	      [<a href="https://github.com/Scarabrine/EECS568Project_Team2_iSAM">Code</a>]<br><br>
          <center>
            <div class="vid">
              <img src="img/victoriaPark.png" width="400">
              <img src="img/JCBB.png" width="400">
	        </div>
          </center>
          <br><br>
	      For my Mobile Robotics course, I worked in a team to implement the <a href="https://www.cc.gatech.edu/~kaess/pub/Kaess08tro.pdf">incremental smoothing and mapping</a> approach to the Simultaneous Localization and Mapping (SLAM) problem. <br><br>Prior to working on this project, I had implemented various state estimation algorithms in Matlab for localization, including the <a href="https://www.youtube.com/watch?v=AM1hES5_WQ4">Extended Kalman Filter</a>, the <a href="https://www.youtube.com/watch?v=xWZ333vlYUE">Unscented Kalman Filter</a>, and the <a href="https://www.youtube.com/watch?v=46N7dpGq4Uw">Particle Filter</a>. This project was unique for me in that it was the first smoothing algorithm I worked with to tackle the SLAM problem. Filtering approaches to SLAM generally estimate the current state of a robot given a sequence of past measurements and actions. However, smoothing approaches improve upon the estimates of the entire sequence of the current and past states of the robot, considering the sequence as an overarching model to be smoothened.
	  <br><br>
	  My main contribution to this project was in the implementation of the <a href="http://webdiis.unizar.es/~jdtardos/papers/Neira_TRA_2001.pdf">joint compatibility branch and bound (JCBB) algorithm</a> for data association. At a single point in time, given a set of N robot sensor measurements and M landmarks, the JCBB algorithm examines various combinations of sensor-landmark mappings and uses the Mahalanobis Distance metric to determine which measurements are most likely to be associated with which landmarks.
      <br><br>
      We applied the iSAM algorithm on the <a href="http://www-personal.acfr.usyd.edu.au/nebot/victoria_park.htm">Victoria Park dataset</a>. The JCBB algorithm proved to be more effective than standard data association methods when we applied it within the iSAM algorithm on the dataset.
	  <br>
	  <br>

		  <p><strong>Trashbot</strong></p>
          [<a href="https://github.com/bonsairobo/trashbot">Code</a>]<br>
          <br>
          <center>
            <div class="vid">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/a6qHyMERqR0?start=29" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	        </div>
          </center>
          <br>
          For my Autonomous Robotics Laboratory senior design course, I collaborated with a team to build a robot that autonomously navigates and detects and removes trash in its environment. The motivation for this project stemmed from noticing the plethora of trash across the UofM campus during football Saturdays. In theory, we could deploy a fleet of these trash collecting robots after a football game to pick up and dispose of various pieces of trash.<br><br>

          We built the robot over a span of 2 months, and it was comprised of various hardware subsystems, including:
          <ul>
            <li>A <a href="https://april.eecs.umich.edu/updates/2015/07/01/magic2.html">MagicBot</a> base</li>
            <li>An Arduino and motor controllers</li>
            <li>A robotic arm</li>
            <li>A Microsoft Kinect</li>
            <li>A PS2 Controller</li>
          </ul>

          My major contribution to this project was in engineering the TrashBot's robotic arm to pick up various objects. My teammate programmatically analyzed point clouds of data from the Microsoft Kinect attached to the robot, and he provided data to the robotic arm representing the centroids of various objects.
          <br><br>
          Given the [x,y,z] position of an object centroid in the frame of the Kinect coordinate system, I used Python to apply homogeneous matrix transformations to convert the coordinates to the frame of the robotic arm's coordinate system. Following that, I implemented a trignometry-based inverse kinematics algorithm to determine the joint angles that the arm would need in order to position its endeffector (claw) over that object's centroid point. Finally, I implemented a state machine to facilate the movement of the arm to pick up and dispose of an object into the TrashBot's onboard trash receptable without collisions. <br><br>

          This experience gave me the opportunity to work with various physical components and it made me very comfortable with getting my hands dirty. We enjoyed many trips to the local hardware store to piece this robot together. It was very rewarding to see the final product!<br><br>

          <center>
            <div class="vid">
              <img src="img/trashbot.jpg" width="400;">
              <img src="img/insideTrashbot.jpg" width="400;"><br><br>
	        </div>
          </center>

		  <p><strong>BotLab Challenge</strong></p>
          <br>
          <center>
            <div class="vid">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/B0mL6WQhMzk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	        </div>
          </center>
          <br>
          For my Autonomous Robotics Laboratory course, I worked in a team to compete in the course's Bot Escape Challenge competition. We were given the UofM April Lab's <a href="https://april.eecs.umich.edu/maebot/">MAEbot</a> platform, and we were tasked with building algorithms to help the MaeBot explore and escape from a wooden maze enclosure.

          <br><br>
          Using C++, we implemented various algorithms on the MAEbot, including:
          <ul>
            <li>A* Path Planning</li>
            <li>Occupancy Grid Mapping</li>
            <li>MonteCarlo Localization</li>
            <li>PID Control</li>
          </ul>

          The experience of implementing the algorithms on the MAEbot and competing in the class competition was very rewarding. There were many robotics concepts that I had learned from simulation and theory, but we found that implementing these algorithms on a real robot would actually be significantly more difficult.

          <br>
          <br>          
	  <p><strong>Kinveval Robot Simulator</strong></p>
          <br>
          <center>
            <div class="vid">
              <img src="img/RRT_Planner.png" width="400">
              <a href="https://www.youtube.com/watch?v=5dlWKZdV9mo"><img src="img/RRTConnect_2D_Kineval.png" width="400"></a>
	        </div>
          </center>

          <br>
          For my Robot Kinematics and Dynamics course, I implemented various robotics algorithms in the <a href="https://github.com/autorob/kineval-stencil">Kineval</a> simulation framework, a Three.js-based platform made by Professor <a href="http://ohseejay.org/">Chad Jenkins</a>.
          <br><br>
          In order to better understand the modeling and control of autonomous agents, I implemented the following features in the framework:<br>
          <ul>
            <li>Path planning via A* algorithm</li>
            <li>Euler and velocity verlet integrator and a PID controller for an inverted pendulum</li>
            <li><a href="https://www.youtube.com/watch?v=7wcBHTCha5o">Finite state machine "dance controller"</a></li>
            <li>Forward kinematics via quaternions and homogeneous matrix transformations</li>
            <li><a href="https://www.youtube.com/watch?v=1tOVkg2UzNM">Inverse kinematics</a> via the Jacobian transpose and Jacobian pseudo-inverse methods</li>
            <li>Motion planning via RRT and <a href="https://www.youtube.com/watch?v=5dlWKZdV9mo">RRT-Connect algorithms in 2D</a> and 3D workspaces</li>
          </ul>
          <center>
            <div class="vid">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/1tOVkg2UzNM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	        </div>
          </center>

		  <br>
          
      	  <p><strong>PID Controller for Magnetically Levitated Ball</strong></p>
          <center>
            <div class="vid">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/BY0sY5yXz3I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
          </center><br>
          For my Control Systems Design course, I worked in a team to build a PID controller in Simulink to control the position of a magnetically levitated ball. Building the controller required first deriving a physical model consisting of the magnetic and gravitational forces acting upon the ball. Aftering deriving the physical model, we linearized the model about the input current required to cause the magnetic force to keep the ball at a constant height. Following that, we tuned our PID controller to meet specifications for steady-state error, settling time, and overshoot.
          <br><br>
        </div>
      </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="other">
        <div class="my-auto">
          <h2 class="mb-5">Other Work</h2>
          <ul>
            <li>
              I wrote this <a href="resources/ethicspaper1.pdf">paper</a> examining the impact of robots and automation on jobs as an assignment for my Robot Ethics course. I find the "Will Robots take Our Jobs?" debate pretty interesting. Here's another <a href="resources/ethicspaper2.pdf">paper</a> I wrote about the ethical concerns for incorporating robots in care for the elderly.
            </li>
            <br>
            <li>
              I made this <a href="https://www.youtube.com/watch?v=yfyMJWaG7Yg">video</a> when I was applying to become an instructional aide for EECS203 Discrete Mathematics at UofM. I am very interested in pedagogy, and I dream of teaching my own class of students someday. 
            </li>
            <br>
            <li>
              Here's a <a href="https://www.youtube.com/watch?v=b2tw21Ra3BU">video</a> of me describing a simulation I helped develop in C++ of the phlebotomy clinic at the UofM Comprehensive Cancer Center. Before I pursued my interest in robotics, I worked on healthcare-related projects for 2 years at the Center for Healthcare and Engineering as a research assistant for Professor <a href="https://amycohn.engin.umich.edu/">Amy Cohn</a>.
            </li>
            <br>
            <li>
              I worked on a year-long team software development project for the UofM Kellogg Eye Center (KEC). Under the guidance of Professor <a href="http://www.andrewdeorio.com/"> Andrew DeOrio </a>, we built a web-based machine learning tool to help ophthalmologists around the world determine the specific gene causing a patient's genetic retinal dystrophy. Here's a <a href="resources/KECPoster.pdf">poster</a> that presents the project.<br><br> For a different project, I made this <a href="https://github.com/ajaayc/kec-class">prototype</a> of a website for KEC to use to distribute educational resources to its residents in ophthalmology.
            </li>
          </ul>
        </div>
      </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="misc">
        <div class="my-auto">
          <h2 class="mb-5">Miscellaneous</h2>

          
          I enjoy playing various board and card games, such as Settlers of Catan, Betrayal, Coup, and StarRealms. I also enjoy watching anime, my favorite shows being Steins; Gate, Code Geass, Attack on Titan, Clannad, and Monster. Recently I have started traveling more, and I'm trying to learn how to play the guitar as well.

          <br><br>
          I grew up in Novi, MI and went to Novi High School. Following that, I went to school at the University of Michigan in Ann Arbor, MI. I consider myself very fortunate to have the support of many people as I pursue my work. My parents always supported me, my growth, and my interests. There is no way I can pay them back for what they have done for me. I have also been fortunate to have many incredible teachers and friends who have always encouraged me to be the best I can be. You know who you are; thank you for everything!<br><br>
        </div>
      </section>

    </div>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/resume.min.js"></script>

    <link rel="stylesheet" type="text/css" href="css/custom.css">

  </body>

</html>
