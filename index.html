<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Ajaay's Personal Page</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/resume.min.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="css/custom.css">

  </head>

  <body id="page-top">

    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">Ajaay's Personal Page</span>
        <span class="d-none d-lg-block">
     		<!-- had img-profile -->			
          <img class="img-fluid rounded-circle mx-auto mb-2" src="img/profile3.JPG" alt="">
        </span>
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About Ajaay</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#projects">Projects</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#other">Other Work</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#misc">Misc. Stuff</a>
          </li>

       </ul>
      </div>
    </nav>

    <div class="container-fluid p-0">

      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <h1 class="mb-0">Ajaay
            <span class="text-primary">Chandrasekaran</span>
          </h1>
          <div class="subheading mb-5">
			  <a href="mailto:ajaay@umich.edu">ajaay [at] umich.edu</a>
          </div>
		  <p class="mb-5">
            Greetings! Welcome to my personal page.
            <br>
            <br>
            I am an aspiring roboticist with a background in software development and mathematics. I pursued my bachelors in computer science and my masters in electrical and computer engineering at the University of Michigan in Ann Arbor, MI.

            <br>
            <br>
            
            My first name <i>Ajaay</i> is a modification of the Indian name <a href="https://en.wikipedia.org/wiki/Ajay_(given_name)"><i>Ajay</i></a>. I respond to many pronunciations of it and have no preference for any of them. The most common pronunciations are Ay-Jay, Uhh-Jay, and Uhh-Jie. <br><br>
            My last name <i>Chandrasekaran</i> is based on the Indian name <a href="https://en.wikipedia.org/wiki/Chandrasekhar"> <i> Chandrasekhar</i></a>. I pronounce it as Chan-dra-say-ker-in.
		  </p>
          <ul class="list-inline list-social-icons mb-0">
            <li class="list-inline-item">
              <a href="https://www.linkedin.com/in/ajaayc/">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://github.com/ajaayc">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://www.youtube.com/channel/UC9jhtzfx7DT13GaAtRYHtLg">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-youtube-play fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <br>
        </div>
      </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="projects">
        <div class="my-auto">
          <h2 class="mb-5">Projects</h2>
          <p> 
		  <p><strong>Collision Estimation for Safe Planning</strong></p>
          [<a href="resources/ajaay_paper.pdf">Paper</a>]<br>
          [Code]
          <center>
            <img src="img/env_setup.png" width="400px;">
            <img src="img/motion_pic.PNG" width="400px;">
          </center>
          <br>
          For my Motion Planning course, I devised and implemented a Gaussian Mixture Model-based algorithm in C++ to expand upon existing methods to estimate the probability that a robot following a pre-generated motion plan would collide with an obstacle.
          <br><br>
          The motivation for this work is that a robot can benefit from quantifying the approximate safety of a motion plan before executing it. While a motion planner should generate a collision-free path, collisions may be possible as the robot follows the path due to natural uncertainty in the data it receives from its sensors and random noise in how it makes movements. <br><br>

          Existing methods to compute the exact probability of collision for a motion plan rely on running thousands of Monte-Carlo simulations of the robot following the motion plan, which is computationally expensive. The goal of this work is to estimate the probability of collision in a lower amount of time.

          Given a probability of collision before executing a motion plan, a robot can either execute it or revise the plan until it can find a "safer" plan.
          <br><br>
          For this work, I utilized the OpenRAVE simulation framework and Armadillo C++ linear algebra library to simulate a linear feedback controller and an Extended Kalman Filter estimate for the position of the PR2 robot as it followed a motion plan. I performed experiments to examine my algorithm's performance and presented my research in a paper and a conference talk.
          <br>
          <br>
          Unfortunately, my algorithm did not perform as well as I had hoped, but I learned much from the experience in regards to conducting independent research.
          <br><br>


		  <p><strong>Deep Neural Network Vehicle Detection System</strong></p>
          [<a href="https://github.com/ajaayc/Car_Detection/blob/master/Perception%20Final%20Report.pdf">Report</a>]<br>
          [<a href="https://github.com/ajaayc/Car_Detection">Code</a>]<br>
          <br>
          <center>
            <img src="img/carBox.jpg" width="400px;">
            <img src="img/graph.png" width="400px;">
          </center><br>
          For my Self-Driving Cars course, I worked in a team to implement a classifier to count the number of cars in an arbitrary image generated from Grand Theft Auto (GTA) simulation. We utilized the TensorFlow Python Object Detector API on AWS EC2 GPU instances to train a fast-RCNN with 50 layers. We trained the RCNN on ~ 6,000 training images with known bounding box locations of cars and we specified two classifications for a detected object: {Car, Not Car}.

          <br><br>
          Using our model, my team ranked 5th place among 35 teams in the class competition by achieving a 63% mean absolute error on the instructor's test set of GTA images with unknown car counts.
          <br><br>

		  <p><strong>Trashbot</strong></p>
          [<a href="https://github.com/bonsairobo/trashbot">Code</a>]<br>
          <br>
          <center>
            <div class="vid">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/a6qHyMERqR0?start=29" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	        </div>
          </center>
          <br>
          For my Autonomous Robotics Laboratory senior design course, I collaborated with a team to build a robot that autonomously navigates and detects and removes trash in its environment. The motivation for this project stemmed from noticing the plethora of trash across the UofM campus during football Saturdays. In theory, we could deploy a fleet of these trash collecting robots after a football game to pick up and dispose of various pieces of trash.<br><br>

          We built the robot over a span of 2 months from the ground up, and it was comprised of various hardware subsystems, including:
          <ul>
            <li>A <a href="https://april.eecs.umich.edu/updates/2015/07/01/magic2.html">MagicBot</a> base</li>
            <li>An Arduino and Motor controllers</li>
            <li>A robotic arm</li>
            <li>A Microsoft Kinect</li>
            <li>A PS2 Controller</li>
          </ul>

          My major contribution to this project was in the getting the TrashBot's robotic arm to function properly. My teammate programmatically analyzed point clouds of data from the Microsoft Kinect attached to the robot, and he provided data to the robotic arm representing the centroids of various objects.
          <br><br>
          Given the [x,y,z] position of an object centroid in the frame of the Kinect coordinate system, I used Python to apply homogeneous matrix transformations to convert the coordinates to the frame of the robotic arm's coordinate system. Following that, I implemented a trignometry-based inverse kinematics algorithm to determine the joint angles that the arm would need in order to position itself over that object's centroid point. Finally, I implemented a state machine to facilate the movement of the arm to pick up and dispose of an object into the MagicBot's onboard trash receptable without collisions. <br><br>

          This experience gave me the opportunity to work with various physical components and it made me very comfortable with getting my hands dirty. We enjoyed many trips to the local hardware store to piece this robot together. It was very rewarding to see the final product!<br><br>

          <center>
            <div class="vid">
              <img src="img/trashbot.jpg" width="400;">
              <img src="img/insideTrashbot.jpg" width="400;"><br><br>
	        </div>
          </center>

		  <p><strong>MDOT Lane Marking Evaluation</strong></p>
          [Code]<br>
          <br>
          <center>
            <div class="vid">
              <img src="img/velodyne.png" width="400;">
              <img src="img/mobileye.JPG" width="400;"><br><br>
	        </div>
          </center>
          <br>

          As a research assistant at the University of Michigan Transportation Research Institute in Ann Arbor, MI, I worked under <a href="http://www.umtri.umich.edu/who-we-are/staff-directory/byoung-keon-daniel-park">Dr. Daniel Park</a> on a project to evaluate the effectiveness of various road lanemarking materials. The project was funded by the Michigan Department of Transportation (MDOT), and our goal was to determine how different lanemarking materials fared over time in the capricious Michigan weather. <br><br>

          A section of the US-23 N highway between Ann Arbor, MI and Brighton, MI was paved with different lanemarking materials along different stretches, and we sought to perform a study over a 2-year span to determine how well each lanemarking material lasted over time.

          <br><br>
          To achieve our goal we needed a way to take measurements of the lanemarkings' conditions on the US-23 highway once during each month so that after the 2-year period we could retrospectively analyze how the lanemarkings' conditions changed over time. Our solution to this problem was to equip a Honda Accord car with various sensors, including:
          <ul>
            <li>Novatel GPS</li>
            <li><a href="https://quanergy.com/m8/">Quanergy M-8 Lidar</a></li>
            <li><a href="https://www.mobileye.com/en-us/">Mobileye unit</a></li>
            <li>Camera</li>
          </ul>
          We proceeded to then engineer a software system that would be executed on the car to collect data of the road conditions from each of these sensors as a human operator drove the car along the US-23 N highway once each month.
          <br><br>
          <center>
            <img src="img/ajaayCar.JPG" width="400;">
          </center>
          <br><br>

          For this project, I developed multi-threaded C++ code utilizing VTK and PCL libraries to extract, interpret, and visualize data collected from our Lidar. We experimented with two Lidar's: The Quanergy M-8 and the Velodyne HDL-64E. Each of these Lidars outputs [x,y,z] point clouds of their surroundings as well as point <a href="http://desktop.arcgis.com/en/arcmap/10.3/manage-data/las-dataset/what-is-intensity-data-.htm">intensities</a>. We were mostly interested in examining the point intensity measurements of the landmarkings. In theory, we could see how the intensity of the points representing lanemarkings changed over time. The degradation of the lanemarkings from the Michigan weather would result in lower intensity points returned by the Lidar for various lanemarking materias.

          <br><br>
          I also developed C++ code to interface with our car's Mobileye unit via the vehicle's CAN message network. The Mobileye communicated data regarding the status of the left and right lanemarkings on the road in front of the driver. Its data arrived in real-time as a sequence of bytes that needed to be converted into a human readable format.
          <br><br>
          Finally, I facilated the collection of data from all four of our sensors simultaneously by helping to create a single module that would run all four sensor collection programs together as individual threads of a single CPU process. The module ran on a single HP i7 laptop during each of the car's monthly drives.
          <br><br>
          I was very proud of our final software system. This project necessitated a wonderful combination of both robotics and computer science knowledge.<br><br>
          <center>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/agMfXfZdug4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </center>
          
          <br><br>

		  <p><strong>BotLab Challenge</strong></p>
          <br>
          <center>
            <div class="vid">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/B0mL6WQhMzk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	        </div>
          </center>
          <br>
          For my Autonomous Robotics Laboratory course, I worked in a team to compete in the course's Bot Escape Challenge competition. We were given the UofM April Lab's <a href="https://april.eecs.umich.edu/maebot/">MAEbot</a> platform, and we were tasked with building algorithms to help the MaeBot explore and escape from a wooden maze enclosure.

          <br><br>
          Using C++, we implemented various algorithms on the MAEbot, including:
          <ul>
            <li>A* Path Planning</li>
            <li>Occupancy Grid Mapping</li>
            <li>MonteCarlo Localization</li>
            <li>PID Control</li>
          </ul>

          The experience of implementing the algorithms on the MAEbot and competing in the class competition was very rewarding. There were many robotics concepts that I had learned from simulation and theory, but we found that implementing these algorithms on a real robot would actually be significantly more difficult.
          
		  </br>
		  </br>
        </div>
      </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="other">
        <div class="my-auto">
          <h2 class="mb-5">Other Work</h2>
          <ul>
            <li>
              I wrote this <a href="resources/ethicspaper1.pdf">paper</a> examining the impact of robots and automation on jobs as an assignment for my Robot Ethics course. I find the "Will Robots take Our Jobs?" debate pretty interesting. Here's another <a href="resources/ethicspaper2.pdf">paper</a> I wrote about the ethical concerns for incorporating robots in care for the elderly.
            </li>
            <br>
            <li>
              I made this <a href="https://www.youtube.com/watch?v=yfyMJWaG7Yg">video</a> when I was applying to become an instructional aide for EECS203 Discrete Mathematics at UofM. I am very interested in pedagogy, and I dream of teaching my own class of students someday. 
            </li>
            <br>
            <li>
              Here's a <a href="https://www.youtube.com/watch?v=b2tw21Ra3BU">video</a> of me talking about a simulation I helped develop in C++ of the phlebotomy clinic at the UofM Comprehensive Cancer Center. Before I pursued my interest in robotics, I worked on healthcare-related projects for 2 years at the Center for Healthcare and Engineering as a research assistant for Professor <a href="https://amycohn.engin.umich.edu/">Amy Cohn</a>.
            </li>
            <br>
            <li>
              I worked on a year-long team software development project for the UofM Kellogg Eye Center (KEC). Under the guidance of Professor <a href="http://www.andrewdeorio.com/"> Andrew DeOrio </a>, we built a web-based machine learning tool to help ophthalmologists around the world determine the specific gene causing a patient's genetic retinal dystrophy. Here's a <a href="resources/KECPoster.pdf">poster</a> that presents the project.<br><br> For a separate project, I also made this <a href="https://github.com/ajaayc/kec-class">prototype</a> of a website for KEC to use to distribute educational resources to residents in ophthalmology.
            </li>
          </ul>
        </div>
      </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="misc">
        <div class="my-auto">
          <h2 class="mb-5">Miscellaneous</h2>
          I'm very proud of myself and where I am today, and it would not have been possible without the support of many people. My parents always supported me, my growth, and my interests. There is no way I can pay them back for what they've done for me. <br><br>I have also been fortunate to have many good friends who've always encouraged me to be the best I can be. You know who you are; thank you for everything!<br><br>
        </div>
      </section>

    </div>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/resume.min.js"></script>

    <link rel="stylesheet" type="text/css" href="css/custom.css">

  </body>

</html>
